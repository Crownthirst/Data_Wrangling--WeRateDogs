{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Project: DATA WRANGLING - WeRateDogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "\n",
    "The first step of the wrangling process is data gathering.\n",
    "\n",
    "In this step I will be looking to gather all three pieces of data that will be needed for this project\n",
    "- The first one being to manually read in the `twitter-archive-enhanced.csv` data downloaded on my workstation\n",
    "- Programmatically downloading the `image-predictions.tsv` data from the [link](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv)\n",
    "- And the third being to query Twitter API using the tweet ID in the `twitter-archive-enhanced.csv` data to gather each tweet's JSON data using Python's tweepy library and store each tweets entire set of JSON data in a file called `tweet_json.txt` file.\n",
    "\n",
    "**First we will go ahead to import all the packages we will be needing for this project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import os\n",
    "import json\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As pointed out earlier we manually read in the first dataset already downloaded into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Requests library we will programmatically download the `image-predictions.tsv` data online, and save it's content into a tsv file, that will be read into a dataframe later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data into file using response.content\n",
    "with open(os.path.join(url.split('/')[-1]), mode= 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally using the Tweepy library, I would query additional data via the Twitter API to gather each tweets JSON data and store the contents in the file `tweet_json.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set consumer key, secret, and access_token and secret\n",
    "#They will be hidden to comply with Twitter API rules\n",
    "consumer_key = 'XXXXXXXXXXXXXXXXXXXXX'\n",
    "consumer_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "access_token = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "access_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "\n",
    "#Set Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n",
      "No Data found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Data found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{888202515573088257: NotFound('404 Not Found\\n144 - No status found with that ID.',), 873697596434513921: NotFound('404 Not Found\\n144 - No status found with that ID.',), 872668790621863937: NotFound('404 Not Found\\n144 - No status found with that ID.',), 872261713294495745: NotFound('404 Not Found\\n144 - No status found with that ID.',), 869988702071779329: NotFound('404 Not Found\\n144 - No status found with that ID.',), 866816280283807744: NotFound('404 Not Found\\n144 - No status found with that ID.',), 861769973181624320: NotFound('404 Not Found\\n144 - No status found with that ID.',), 856602993587888130: NotFound('404 Not Found\\n144 - No status found with that ID.',), 856330835276025856: NotFound('404 Not Found\\n144 - No status found with that ID.',), 851953902622658560: NotFound('404 Not Found\\n144 - No status found with that ID.',), 851861385021730816: NotFound('404 Not Found\\n144 - No status found with that ID.',), 845459076796616705: NotFound('404 Not Found\\n144 - No status found with that ID.',), 844704788403113984: NotFound('404 Not Found\\n144 - No status found with that ID.',), 842892208864923648: NotFound('404 Not Found\\n144 - No status found with that ID.',), 837366284874571778: NotFound('404 Not Found\\n144 - No status found with that ID.',), 837012587749474308: NotFound('404 Not Found\\n144 - No status found with that ID.',), 829374341691346946: NotFound('404 Not Found\\n144 - No status found with that ID.',), 827228250799742977: NotFound('404 Not Found\\n144 - No status found with that ID.',), 812747805718642688: NotFound('404 Not Found\\n144 - No status found with that ID.',), 802247111496568832: NotFound('404 Not Found\\n144 - No status found with that ID.',), 779123168116150273: NotFound('404 Not Found\\n144 - No status found with that ID.',), 775096608509886464: NotFound('404 Not Found\\n144 - No status found with that ID.',), 771004394259247104: Forbidden('403 Forbidden\\n179 - Sorry, you are not authorized to see this status.',), 770743923962707968: NotFound('404 Not Found\\n144 - No status found with that ID.',), 766864461642756096: NotFound('404 Not Found\\n144 - No status found with that ID.',), 759923798737051648: NotFound('404 Not Found\\n144 - No status found with that ID.',), 759566828574212096: NotFound('404 Not Found\\n144 - No status found with that ID.',), 754011816964026368: NotFound('404 Not Found\\n144 - No status found with that ID.',), 680055455951884288: NotFound('404 Not Found\\n144 - No status found with that ID.',)}\n"
     ]
    }
   ],
   "source": [
    "#Query Twitter's API for JSON data for each tweet id in the dataframe\n",
    "'''\n",
    "id_of_tweet = df.tweet_id\n",
    "count = 0\n",
    "failed = {}\n",
    "#Save output in a newline in a txt file\n",
    "with open('tweet_json.txt', mode= 'w') as outputfile:\n",
    "    for idx in id_of_tweet:\n",
    "        count += 1\n",
    "        try:\n",
    "            tweet = api.get_status(idx, tweet_mode= 'extended')\n",
    "            json.dump(tweet._json, outputfile)\n",
    "            outputfile.write('\\n')\n",
    "        \n",
    "        except tweepy.errors.TweepyException as e:\n",
    "            print('No Data found')\n",
    "            failed[idx] = e\n",
    "            pass\n",
    "print(failed)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the `tweet_json.txt` file by line into a pandas dataframe with variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "with open('tweet_json.txt', mode= 'r') as json_file:\n",
    "    for text in json_file:\n",
    "        texts = json.loads(text)\n",
    "        tweet_id = texts['id']\n",
    "        retweet_count = texts['retweet_count']\n",
    "        favorite_count = texts['favorite_count']\n",
    "        tweet_date = texts['created_at']\n",
    "        tweet_source = texts['source']\n",
    "        json_list.append({'tweet_id' : tweet_id,\n",
    "                       'retweet_count' : retweet_count,\n",
    "                       'favorite_count' : favorite_count,\n",
    "                       'tweet_date' : tweet_date,\n",
    "                       'tweet_source' : tweet_source})\n",
    "\n",
    "df_json = pd.DataFrame(json_list, columns = ['tweet_id', 'retweet_count','favorite_count','tweet_date','tweet_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>6981</td>\n",
       "      <td>33737</td>\n",
       "      <td>Tue Aug 01 16:23:56 +0000 2017</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>5284</td>\n",
       "      <td>29265</td>\n",
       "      <td>Tue Aug 01 00:17:27 +0000 2017</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>3468</td>\n",
       "      <td>22000</td>\n",
       "      <td>Mon Jul 31 00:18:03 +0000 2017</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>7203</td>\n",
       "      <td>36844</td>\n",
       "      <td>Sun Jul 30 15:58:51 +0000 2017</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>7727</td>\n",
       "      <td>35231</td>\n",
       "      <td>Sat Jul 29 16:00:24 +0000 2017</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>36</td>\n",
       "      <td>88</td>\n",
       "      <td>Mon Nov 16 00:24:50 +0000 2015</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>115</td>\n",
       "      <td>246</td>\n",
       "      <td>Mon Nov 16 00:04:52 +0000 2015</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>36</td>\n",
       "      <td>100</td>\n",
       "      <td>Sun Nov 15 23:21:54 +0000 2015</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>39</td>\n",
       "      <td>112</td>\n",
       "      <td>Sun Nov 15 23:05:30 +0000 2015</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>421</td>\n",
       "      <td>2286</td>\n",
       "      <td>Sun Nov 15 22:32:08 +0000 2015</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2327 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id  retweet_count  favorite_count  \\\n",
       "0     892420643555336193           6981           33737   \n",
       "1     892177421306343426           5284           29265   \n",
       "2     891815181378084864           3468           22000   \n",
       "3     891689557279858688           7203           36844   \n",
       "4     891327558926688256           7727           35231   \n",
       "...                  ...            ...             ...   \n",
       "2322  666049248165822465             36              88   \n",
       "2323  666044226329800704            115             246   \n",
       "2324  666033412701032449             36             100   \n",
       "2325  666029285002620928             39             112   \n",
       "2326  666020888022790149            421            2286   \n",
       "\n",
       "                          tweet_date  \\\n",
       "0     Tue Aug 01 16:23:56 +0000 2017   \n",
       "1     Tue Aug 01 00:17:27 +0000 2017   \n",
       "2     Mon Jul 31 00:18:03 +0000 2017   \n",
       "3     Sun Jul 30 15:58:51 +0000 2017   \n",
       "4     Sat Jul 29 16:00:24 +0000 2017   \n",
       "...                              ...   \n",
       "2322  Mon Nov 16 00:24:50 +0000 2015   \n",
       "2323  Mon Nov 16 00:04:52 +0000 2015   \n",
       "2324  Sun Nov 15 23:21:54 +0000 2015   \n",
       "2325  Sun Nov 15 23:05:30 +0000 2015   \n",
       "2326  Sun Nov 15 22:32:08 +0000 2015   \n",
       "\n",
       "                                           tweet_source  \n",
       "0     <a href=\"http://twitter.com/download/iphone\" r...  \n",
       "1     <a href=\"http://twitter.com/download/iphone\" r...  \n",
       "2     <a href=\"http://twitter.com/download/iphone\" r...  \n",
       "3     <a href=\"http://twitter.com/download/iphone\" r...  \n",
       "4     <a href=\"http://twitter.com/download/iphone\" r...  \n",
       "...                                                 ...  \n",
       "2322  <a href=\"http://twitter.com/download/iphone\" r...  \n",
       "2323  <a href=\"http://twitter.com/download/iphone\" r...  \n",
       "2324  <a href=\"http://twitter.com/download/iphone\" r...  \n",
       "2325  <a href=\"http://twitter.com/download/iphone\" r...  \n",
       "2326  <a href=\"http://twitter.com/download/iphone\" r...  \n",
       "\n",
       "[2327 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       "       '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>',\n",
       "       '<a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>',\n",
       "       '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_json.tweet_source.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data\n",
    "In this section, detect and document at least **eight (8) quality issues and two (2) tidiness issue**. You must use **both** visual assessment\n",
    "programmatic assessement to assess the data.\n",
    "\n",
    "**Note:** pay attention to the following key points when you access the data.\n",
    "\n",
    "* You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3.\n",
    "\n",
    "4.\n",
    "\n",
    "5.\n",
    "\n",
    "6.\n",
    "\n",
    "7.\n",
    "\n",
    "8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Tidiness issues\n",
    "1.\n",
    "\n",
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Cleaning Data\n",
    "In this section, clean **all** of the issues you documented while assessing. \n",
    "\n",
    "**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of original pieces of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
